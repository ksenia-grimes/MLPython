{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from matplotlib import pyplot as plt\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df = pd.read_csv(\"imdb.csv\")\n",
    "#df = pd.read_csv('newsPOLITIKA.csv', index_col = 0)\n",
    "#df['rubric'] = 0\n",
    "#df['rubric'][0:1]='политика'\n",
    "#df['rubric'][2:5]='сибирь'\n",
    "#del df['Unnamed']\n",
    "#df.set_index(df.columns[0])\n",
    "#sentimentbinary = df['sentiment']\n",
    "# приводим к бинарному признаку\n",
    "df['sentimentbinary'] = df['sentiment'].map({'negative': 0, 'positive': 1})\n",
    "X = df['review']\n",
    "y = df['sentimentbinary']\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.2)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#чтобы не попадались несущественные слова\n",
    "ENGLISH_STOP_WORDS = set([\n",
    "    'a',\n",
    "    'about',\n",
    "    'above',\n",
    "    'across',\n",
    "    'after',\n",
    "    'afterwards',\n",
    "    'again',\n",
    "    'against',\n",
    "    'ain',\n",
    "    'all',\n",
    "    'almost',\n",
    "    'alone',\n",
    "    'along',\n",
    "    'already',\n",
    "    'also',\n",
    "    'although',\n",
    "    'always',\n",
    "    'am',\n",
    "    'among',\n",
    "    'amongst',\n",
    "    'amoungst',\n",
    "    'amount',\n",
    "    'an',\n",
    "    'and',\n",
    "    'another',\n",
    "    'any',\n",
    "    'anyhow',\n",
    "    'anyone',\n",
    "    'anything',\n",
    "    'anyway',\n",
    "    'anywhere',\n",
    "    'are',\n",
    "    'aren',\n",
    "    'around',\n",
    "    'as',\n",
    "    'at',\n",
    "    'back',\n",
    "    'be',\n",
    "    'became',\n",
    "    'because',\n",
    "    'become',\n",
    "    'becomes',\n",
    "    'becoming',\n",
    "    'been',\n",
    "    'before',\n",
    "    'beforehand',\n",
    "    'behind',\n",
    "    'being',\n",
    "    'below',\n",
    "    'beside',\n",
    "    'besides',\n",
    "    'between',\n",
    "    'beyond',\n",
    "    'bill',\n",
    "    'both',\n",
    "    'bottom',\n",
    "    'but',\n",
    "    'by',\n",
    "    'call',\n",
    "    'can',\n",
    "    'cannot',\n",
    "    'cant',\n",
    "    'co',\n",
    "    'con',\n",
    "    'could',\n",
    "    'couldn',\n",
    "    'couldnt',\n",
    "    'cry',\n",
    "    'd',\n",
    "    'de',\n",
    "    'describe',\n",
    "    'detail',\n",
    "    'did',\n",
    "    'didn',\n",
    "    'do',\n",
    "    'does',\n",
    "    'doesn',\n",
    "    'doing',\n",
    "    'don',\n",
    "    'done',\n",
    "    'down',\n",
    "    'due',\n",
    "    'during',\n",
    "    'each',\n",
    "    'eg',\n",
    "    'eight',\n",
    "    'either',\n",
    "    'eleven',\n",
    "    'else',\n",
    "    'elsewhere',\n",
    "    'empty',\n",
    "    'enough',\n",
    "    'etc',\n",
    "    'even',\n",
    "    'ever',\n",
    "    'every',\n",
    "    'everyone',\n",
    "    'everything',\n",
    "    'everywhere',\n",
    "    'except',\n",
    "    'few',\n",
    "    'fifteen',\n",
    "    'fify',\n",
    "    'fill',\n",
    "    'find',\n",
    "    'fire',\n",
    "    'first',\n",
    "    'five',\n",
    "    'for',\n",
    "    'former',\n",
    "    'formerly',\n",
    "    'forty',\n",
    "    'found',\n",
    "    'four',\n",
    "    'from',\n",
    "    'front',\n",
    "    'full',\n",
    "    'further',\n",
    "    'get',\n",
    "    'give',\n",
    "    'go',\n",
    "    'had',\n",
    "    'hadn',\n",
    "    'has',\n",
    "    'hasn',\n",
    "    'hasnt',\n",
    "    'have',\n",
    "    'haven',\n",
    "    'having',\n",
    "    'he',\n",
    "    'hence',\n",
    "    'her',\n",
    "    'here',\n",
    "    'hereafter',\n",
    "    'hereby',\n",
    "    'herein',\n",
    "    'hereupon',\n",
    "    'hers',\n",
    "    'herself',\n",
    "    'him',\n",
    "    'himself',\n",
    "    'his',\n",
    "    'how',\n",
    "    'however',\n",
    "    'hundred',\n",
    "    'i',\n",
    "    'ie',\n",
    "    'if',\n",
    "    'in',\n",
    "    'inc',\n",
    "    'indeed',\n",
    "    'interest',\n",
    "    'into',\n",
    "    'is',\n",
    "    'isn',\n",
    "    'it',\n",
    "    'its',\n",
    "    'itself',\n",
    "    'just',\n",
    "    'keep',\n",
    "    'last',\n",
    "    'latter',\n",
    "    'latterly',\n",
    "    'least',\n",
    "    'less',\n",
    "    'll',\n",
    "    'ltd',\n",
    "    'm',\n",
    "    'ma',\n",
    "    'made',\n",
    "    'many',\n",
    "    'may',\n",
    "    'me',\n",
    "    'meanwhile',\n",
    "    'might',\n",
    "    'mightn',\n",
    "    'mill',\n",
    "    'mine',\n",
    "    'more',\n",
    "    'moreover',\n",
    "    'most',\n",
    "    'mostly',\n",
    "    'move',\n",
    "    'much',\n",
    "    'must',\n",
    "    'mustn',\n",
    "    'my',\n",
    "    'myself',\n",
    "    'name',\n",
    "    'namely',\n",
    "    'needn',\n",
    "    'neither',\n",
    "    'never',\n",
    "    'nevertheless',\n",
    "    'next',\n",
    "    'nine',\n",
    "    'no',\n",
    "    'nobody',\n",
    "    'none',\n",
    "    'noone',\n",
    "    'nor',\n",
    "    'not',\n",
    "    'nothing',\n",
    "    'now',\n",
    "    'nowhere',\n",
    "    'o',\n",
    "    'of',\n",
    "    'off',\n",
    "    'often',\n",
    "    'on',\n",
    "    'once',\n",
    "    'one',\n",
    "    'only',\n",
    "    'onto',\n",
    "    'or',\n",
    "    'other',\n",
    "    'others',\n",
    "    'otherwise',\n",
    "    'our',\n",
    "    'ours',\n",
    "    'ourselves',\n",
    "    'out',\n",
    "    'over',\n",
    "    'own',\n",
    "    'part',\n",
    "    'per',\n",
    "    'perhaps',\n",
    "    'please',\n",
    "    'put',\n",
    "    'rather',\n",
    "    're',\n",
    "    's',\n",
    "    'same',\n",
    "    'see',\n",
    "    'seem',\n",
    "    'seemed',\n",
    "    'seeming',\n",
    "    'seems',\n",
    "    'serious',\n",
    "    'several',\n",
    "    'shan',\n",
    "    'she',\n",
    "    'should',\n",
    "    'shouldn',\n",
    "    'show',\n",
    "    'side',\n",
    "    'since',\n",
    "    'sincere',\n",
    "    'six',\n",
    "    'sixty',\n",
    "    'so',\n",
    "    'some',\n",
    "    'somehow',\n",
    "    'someone',\n",
    "    'something',\n",
    "    'sometime',\n",
    "    'sometimes',\n",
    "    'somewhere',\n",
    "    'still',\n",
    "    'such',\n",
    "    'system',\n",
    "    't',\n",
    "    'take',\n",
    "    'ten',\n",
    "    'than',\n",
    "    'that',\n",
    "    'the',\n",
    "    'their',\n",
    "    'theirs',\n",
    "    'them',\n",
    "    'themselves',\n",
    "    'then',\n",
    "    'thence',\n",
    "    'there',\n",
    "    'thereafter',\n",
    "    'thereby',\n",
    "    'therefore',\n",
    "    'therein',\n",
    "    'thereupon',\n",
    "    'these',\n",
    "    'they',\n",
    "    'thick',\n",
    "    'thin',\n",
    "    'third',\n",
    "    'this',\n",
    "    'those',\n",
    "    'though',\n",
    "    'three',\n",
    "    'through',\n",
    "    'throughout',\n",
    "    'thru',\n",
    "    'thus',\n",
    "    'to',\n",
    "    'together',\n",
    "    'too',\n",
    "    'top',\n",
    "    'toward',\n",
    "    'towards',\n",
    "    'twelve',\n",
    "    'twenty',\n",
    "    'two',\n",
    "    'un',\n",
    "    'under',\n",
    "    'until',\n",
    "    'up',\n",
    "    'upon',\n",
    "    'us',\n",
    "    've',\n",
    "    'very',\n",
    "    'via',\n",
    "    'was',\n",
    "    'wasn',\n",
    "    'we',\n",
    "    'well',\n",
    "    'were',\n",
    "    'weren',\n",
    "    'what',\n",
    "    'whatever',\n",
    "    'when',\n",
    "    'whence',\n",
    "    'whenever',\n",
    "    'where',\n",
    "    'whereafter',\n",
    "    'whereas',\n",
    "    'whereby',\n",
    "    'wherein',\n",
    "    'whereupon',\n",
    "    'wherever',\n",
    "    'whether',\n",
    "    'which',\n",
    "    'while',\n",
    "    'whither',\n",
    "    'who',\n",
    "    'whoever',\n",
    "    'whole',\n",
    "    'whom',\n",
    "    'whose',\n",
    "    'why',\n",
    "    'will',\n",
    "    'with',\n",
    "    'within',\n",
    "    'without',\n",
    "    'won',\n",
    "    'would',\n",
    "    'wouldn',\n",
    "    'y',\n",
    "    'yet',\n",
    "    'you',\n",
    "    'your',\n",
    "    'yours',\n",
    "    'yourself',\n",
    "    'yourselves',\n",
    "    'year',\n",
    "    'years',\n",
    "    'acting',\n",
    "    'action',\n",
    "    'actor',\n",
    "    'actors',\n",
    "    'watch',\n",
    "    'watched',\n",
    "    'watching',\n",
    "    'movie',\n",
    "    'movies',\n",
    "    'scene',\n",
    "    'scenes',\n",
    "    'script',\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#векторизация и деление датасета на обучающую и тест-часть\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(stop_words = ENGLISH_STOP_WORDS, max_features=500)\n",
    "X_vec = vectorizer.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vec, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8902490176272685"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Мультиномиальный\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnb = MultinomialNB()\n",
    "train = X_train\n",
    "target = y_train\n",
    "model = mnb.fit(train,target)\n",
    "#тестируем, проверяем точность\n",
    "roc_auc_score(y_test, mnb.predict_proba(X_test)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8928959119310187"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Случайный лес\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier(n_estimators = 150)#между 150 и 250 точность незначительно повышается\n",
    "forest = forest.fit(X_train,y_train)\n",
    "roc_auc_score(y_test, forest.predict_proba(X_test)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7835203744240525"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "tree = tree.DecisionTreeClassifier(random_state=0,max_depth=12) #>12 у меня снижается roc_auc_score\n",
    "tree = tree.fit(X_train, y_train)\n",
    "roc_auc_score(y_test, tree.predict_proba(X_test)[:, 1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
